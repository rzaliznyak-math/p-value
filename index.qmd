---
title: "What The Heck Is a P-Value?"
subtitle: "And How Not To Abuse It"
author: "Russ Zaliznyak <[rzaliznyak@gmail.com](mailto:rzaliznyak@gmail.com)>"
date: "2024-11-23"
execute:
  echo: false
format: 
  html: 
    css: style.css
    toc: true
    toc-expand: true
    toc-indent: 1em
jupyter: python3
---


# Introduction

If you’ve ever conducted an A/B test, you’ve encountered a p-value. Understanding what it is is crucial for accurately interpreting your test results. Even those with a strong stats background have been known to misuse and abuse p-values.

Let’s define key terms that will enable us to understand the role of p-values in A/B testing so that we may use them properly.

## Definitions

### **Null Hypothesis**: Assumption of Innocence

The _**Null Hypothesis**_ represents our current beliefs of the truth. You can think of the null hypothesis as sticking a stake in the ground and declaring, "This is where we stand". We require evidence to in order to declare the hypothesis false.

- Example #1: Defendent did not steal the loaf of broad
- Example #2: Website A performs exactly like Website B


### **Significance Test**: Our Claim Is On Trial

A Significance Test is like a jury trial. During this test, we collect and weigh the evidence to decide whether to reject or retain our _**Null Hypothesis**_.

### **Alternative Hypothesis**: What Are the Charges?

Think of the _**Alternative Hypothesis**_ as the charges our defendent is facing. If we collect enough evidence to reject the _Null_, the _Alternative_ becomes our new working theory.

- Example #1: Defendent stole the loaf of bread
- Example #2: Website A and Website B perform differently

### **Statistical Significance**: Guilty!

Our trial has concluded and the evidence shows that our _Null Hypothesis_ is unreasonable. The jury declares our result _**Statistically Significanct**_ and we are forced to reject the _Null_, while accepting the _Alternative_ as true.

- Example 1: Defendent is guilty of stealing the loaf of bread
- Example 2: Website A and Website B are guilty of performing differently

### **P-value**: A Measure of Reasonableness

Once our evidence is collected and analyzed, how do we know if our _Null Hypothesis_ is unreasonable?
For this definition, we must be more precise than our previous terms.

_**P-Value**_: Assuming the _Null Hypothesis_ is true, what's the chance of seeing our evidence (or more extreme)?

In order to build our intuition for this definition, we're going to simulate conversion events from two absolutely identical websites. If you haven't already, check out our previous paper on [**The Power of Data Simulation**](https://rzaliznyak-math.github.io/random){target="_blank"}.

## Example: Website A vs Website A
